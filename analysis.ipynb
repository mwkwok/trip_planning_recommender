{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip planning recommender\n",
    "\n",
    "This notebook is to build a trip planning recommender that suggests traveling areas to travelers. The suggesting areas are concentrated with attractive and functional venues of the travelers’ need. \n",
    "\n",
    "![Image7](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c07.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Libraries #####\n",
    "import os, re, folium, requests, time, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.path as mplPath\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from ipywidgets import Checkbox, Button, VBox, HTML, Output, IntSlider\n",
    "from xml.dom.minidom import parse\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import clear_output\n",
    "\n",
    "##### Constants #####\n",
    "# Area radius\n",
    "RADIUS = 500\n",
    "\n",
    "##### Helper functions #####\n",
    "def parseVertices(v):\n",
    "    v = v.lstrip(' ')\n",
    "    latlng = np.array([[float(p.split(',')[1]), float(p.split(',')[0])] for p in v.split(' ')])\n",
    "    return ( mplPath.Path(latlng), np.mean(latlng, axis=0), np.min(latlng, axis=0), np.max(latlng, axis=0) )\n",
    "\n",
    "def distance(loc1, loc2):\n",
    "    lat1, lng1, lat2, lng2 = list(map(radians, [loc1[0], loc1[1], loc2[0], loc2[1]]))\n",
    "    a = sin( (lat2-lat1)/2 )**2 + cos(lat1) * cos(lat2) * sin( (lng2-lng1)/2 )**2\n",
    "    return 2 * 6373. * 1000 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "def descfunc1(e):\n",
    "    return {row.find_all()[0].text: row.find_all()[1].text\n",
    "        for row in BeautifulSoup(e, 'html.parser').find('table').find('table').find_all('tr') }\n",
    "\n",
    "def descfunc2(e):\n",
    "    return {row.find_all()[0].text: row.find_all()[1].text\n",
    "        for row in BeautifulSoup(e, 'html.parser').find('table').find_all('tr') }\n",
    "\n",
    "def corrfunc1(e):\n",
    "    return {'venue_lng':float(e.split(',')[0]),'venue_lat':float(e.split(',')[1])}\n",
    "\n",
    "def mergeDict(a, b):\n",
    "    a.update(b)\n",
    "    return a\n",
    "\n",
    "def divide(a,b):\n",
    "    return 1 if a==0 and b==0 else None if b== 0 else a/b\n",
    "\n",
    "def normalize(series, importance):\n",
    "    def linear(series, cutoff):\n",
    "        return pd.Series([divide(min(x,cutoff),cutoff) for x in series], index=series.index)\n",
    "\n",
    "    cutoff = series[series>0].quantile(importance/10) if len(series[series>0]) else 0\n",
    "    return importance * linear(series, cutoff)\n",
    "\n",
    "def pairup(loc1):\n",
    "    for name, loc2 in zip(names, locs):\n",
    "        if distance(loc1, loc2) < RADIUS:\n",
    "            return pd.Series({'name':name,'lat':loc2[0],'lng':loc2[1]})\n",
    "    return pd.Series({'name':np.nan,'lat':np.nan,'lng':np.nan})\n",
    "\n",
    "def getAddress(loc):\n",
    "    geolocator = Nominatim(user_agent=\"trip_planning_recommender__\")\n",
    "    while True:\n",
    "        try:\n",
    "            return geolocator.reverse(loc).address\n",
    "        except Exception as e:\n",
    "            time.sleep(0.5)\n",
    "\n",
    "def randColor(n):\n",
    "    colors = []\n",
    "    np.random.seed(2)\n",
    "    while len(colors) < n:\n",
    "        cand = np.random.randint(0,255,3)\n",
    "        if any([ch<30 for color in colors for ch in np.abs(color-cand)]):\n",
    "            continue\n",
    "        colors.append(cand)\n",
    "    return ['#%02x%02x%02x'%tuple(color) for color in colors]\n",
    "            \n",
    "def randColor2(n):\n",
    "    options = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue',\n",
    "             'darkpurple', 'white', 'pink', 'lightblue', 'lightgreen', 'gray', 'black', 'lightgray']\n",
    "    np.random.seed(2)\n",
    "    np.random.shuffle(options)\n",
    "    return options[:n]\n",
    "\n",
    "def getAlbumHtml(pictDF):\n",
    "    pictDF = pictDF.sample(frac=1)\n",
    "    album_html = ''\n",
    "    for i, row in pictDF.reset_index(drop=True).iterrows():\n",
    "        if i%3==0: \n",
    "            album_html += '<tr>'\n",
    "        album_html += '''<td width=240 valign=\"top\">\n",
    "                         <img src=\"%s\" height=180 width=240><br><font size=2>%s</font></td>'''\\\n",
    "                        %(row['PhotoURL'], row['Description'])\n",
    "        if i%3==2:\n",
    "            album_html += '</tr>'\n",
    "        if i == 8:\n",
    "            break\n",
    "    return album_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - area candidates\n",
    "\n",
    "  We need a list of circular area candidates to choose from in order to make recommendations.\n",
    "  \n",
    "  Each candidate is represent by a point, which is generated by:\n",
    "  \n",
    "  1. Sample random points in Singapore (Central, East regions);\n",
    "  2. Reject a point if a new area is overlapped with existings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### Get geo polygons that defines Singapore's boundaries\n",
    "##### The polygons is used for generating random points.\n",
    "##### Return a dict of {region_name: (polygon, center_latlng, upperleft_latlng, lowerright_latlng)}\n",
    "\n",
    "polykml = './data.gov.sg/regions/master-plan-2014-region-boundary-web/MP14_REGION_WEB_PL.kml'\n",
    "polys   = {pm.getElementsByTagName('name')[0].firstChild.data: \n",
    "              [parseVertices(ob.getElementsByTagName('coordinates')[0].firstChild.data )\n",
    "                  for ob in pm.getElementsByTagName('outerBoundaryIs')]\n",
    "                      for pm in parse(polykml).getElementsByTagName('Placemark')}\n",
    "\n",
    "##### Generate a list of areas\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(2)\n",
    "names, locs, streets = [], [], []\n",
    "                \n",
    "# loop over all regions. Each region can have more than one polygon.\n",
    "for name,  regions in polys.items():\n",
    "    # Confine regions\n",
    "    if name not in ['CENTRAL REGION', 'EAST REGION', 'NORTH REGION']:\n",
    "        continue\n",
    "        \n",
    "    # keep generating until no new valid points\n",
    "    for i, (poly, center, ul, br) in enumerate(regions):\n",
    "        donecnt = 0\n",
    "        failcnt = 0\n",
    "        while failcnt < 2000:\n",
    "            sample = [np.random.uniform(ul[0],br[0]), np.random.uniform(ul[1],br[1])]\n",
    "            \n",
    "            # test if it is a valid new point. If not, failcnt increments and finally ends the loop\n",
    "            if poly.contains_point(sample) and not any([distance(loc,sample)<2*RADIUS for loc in locs]):\n",
    "                names.append('%s-%02d-%02d'%(name,i,donecnt))\n",
    "                locs.append(sample)\n",
    "                streets.append(getAddress(sample))\n",
    "                donecnt += 1\n",
    "            else:\n",
    "                failcnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Plot all candidates out\n",
    "\n",
    "# get center latlng\n",
    "centerLoc = np.mean(locs, axis=0)\n",
    "\n",
    "# create map and add marks for areas\n",
    "mapArea = folium.Map(location=centerLoc, zoom_start=11)\n",
    "for name, street, loc in zip(names, streets, locs):\n",
    "    folium.Circle(loc, RADIUS, name, street, color='blue', fill=True, fill_color='#3186cc', fill_opacity=0.7)\\\n",
    "          .add_to(mapArea)  \n",
    "display(mapArea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image5](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - Venues near areas from FourSquare API\n",
    "\n",
    "  Now that we have a list of areas, we query venues near each area.\n",
    "  \n",
    "  1. Begin with getting venue category definitions of the API;\n",
    "  2. We limit to use a small group of categories as there is query limitation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# regions 259\n"
     ]
    }
   ],
   "source": [
    "CLIENT_ID     = 'AYZYQLIYYKRRE4X3FLPAQVZYVY3YDRAAP5XFI2FYG2BWMRVM' # Foursquare ID\n",
    "CLIENT_SECRET = 'L3WZNFI0BOIEAW4Z2S25ADX12XBSLT53Z1HGHY2T5P14IZPD' # Foursquare Secret\n",
    "\n",
    "##### Get category definitions. The API returns a JSON, from which we get a list of paths\n",
    "##### Each path describes a final category and its parent categories.\n",
    "##### /<Cat ID>:<Cat Name>/<...>/<Cat ID>:<Cat Name>\n",
    "\n",
    "url  = ''.join(['https://api.foursquare.com/v2/venues/categories?&client_id=',CLIENT_ID,'&client_secret=',CLIENT_SECRET,'&v=20180605'])\n",
    "tmps = [('',requests.get(url).json()['response']['categories'])]\n",
    "\n",
    "# cNID collects all paths\n",
    "cNID = []\n",
    "while tmps:\n",
    "    path, tmp = tmps.pop()\n",
    "    for t in tmp:\n",
    "        cat  = t.get('categories',[])\n",
    "        path = '%s//%s:%s'%(path, t.get('id','_'), t.get('name','_'))\n",
    "        if cat:\n",
    "            tmps.append((path, cat))\n",
    "        else:\n",
    "            cNID.append( path)\n",
    "\n",
    "# categories of interest\n",
    "cats = ['American Restaurant','Basketball Court','Church','Bank','Café','Gym',\n",
    "        'Asian Restaurant','Supermarket','Shopping Mall','Laundry Service','Market','Hospital',]\n",
    "\n",
    "# category map that maps child category names to categories of interest\n",
    "cmap = { level.split(':')[-1]:cat\n",
    "            for cat in cats \n",
    "                for nid in cNID if re.match('.*:%s$'%cat, nid) or re.match('.*:%s//'%cat, nid)\n",
    "                       for level in re.split(':%s', nid)[-1].split('//')}\n",
    "\n",
    "# a list of category IDs \n",
    "cids = [nid.split('//')[-1].split(':')[0] for cat in cats for nid in cNID if re.match('.*:%s$'%cat, nid)]\n",
    "\n",
    "##### Helper function: getNearbyVenues\n",
    "##### It loops through areas and obtain nearyby venues of category of interest\n",
    "\n",
    "def getNearbyVenues(names, locs, radius=RADIUS):\n",
    "    venues=[]\n",
    "    for name, (lat, lng) in zip(names, locs):\n",
    "        nCalls = 2 # divide one call into two\n",
    "        for j in range(nCalls): \n",
    "            size = int(np.ceil(len(cids)/nCalls))\n",
    "            cid = ','.join(cids[j*size:(j+1)*size])\n",
    "            \n",
    "            url = ['https://api.foursquare.com/v2/venues/explore?&client_id=',CLIENT_ID,'&client_secret=',CLIENT_SECRET,\n",
    "                   '&v=20180605','&ll=',lat,',',lng,'&radius=',radius,'&limit=500','&categoryId=',cid]\n",
    "            url = ''.join([str(x) for x in url])\n",
    "            for i in range(10):\n",
    "                try:\n",
    "                    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "                    break\n",
    "                except:\n",
    "                    print('retrying', i)\n",
    "\n",
    "            venues.extend([{'name':name,'lat':lat,'lng':lng,\n",
    "                            'venue':v['venue']['name'],\n",
    "                            'venue_lat':v['venue']['location']['lat'],\n",
    "                            'venue_lng':v['venue']['location']['lng'],\n",
    "                            'venue_cat':v['venue']['categories'][0]['name']} for v in results])\n",
    "    return pd.DataFrame(venues)\n",
    "\n",
    "# get nearby venues\n",
    "print('# regions', len(names))\n",
    "venues = getNearbyVenues(names, locs)\n",
    "\n",
    "# map names\n",
    "venues['venue_cat'] = venues['venue_cat'].replace(cmap)\n",
    "venues = venues[venues['venue_cat'].isin(cats)]\n",
    "venues = venues.merge(pd.DataFrame({'name':names,'address':streets}), on='name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - Venue data from data.gov.sg\n",
    "\n",
    "  data.gov.sg offers datasets for attraction spots, hotels and so on with photo URLs and other useful attributes.\n",
    "  \n",
    "  Here we will load 7 download datasets, for hotels, attractions, museums, heritage trees, heritage sites, libraries, and parks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper function: parseKML()\n",
    "def parseKML(cat, kml):\n",
    "    try:\n",
    "        desc = [descfunc1(e.text) for e in ET.parse(kml).getroot().iter() if 'description' in e.tag]\n",
    "    except:\n",
    "        desc = [descfunc2(e.text) for e in ET.parse(kml).getroot().iter() if 'description' in e.tag]\n",
    "    try:\n",
    "        corr = [corrfunc1(e.text) for e in ET.parse(kml).getroot().iter() if 'coordinates' in e.tag]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    tmp = pd.DataFrame([mergeDict(c,d) for d, c in zip(desc, corr)])\n",
    "    \n",
    "    cols = ['NAME', 'DESCRIPTION', 'PHOTOURL', 'venue_lat', 'venue_lng', 'address']\n",
    "    for col in cols:\n",
    "        if col not in tmp:\n",
    "            tmp[col] = np.nan\n",
    "\n",
    "    tmp = tmp[cols].replace('<Null>', np.nan)\\\n",
    "                   .rename(columns={'NAME':'venue','DESCRIPTION':'Description','PHOTOURL':'PhotoURL'})\n",
    "    tmp['venue_cat'] =  'Park'           if 'NATIONALPARKS'  in cat else\\\n",
    "                        'Attraction'     if 'TOURISM'        in cat else\\\n",
    "                        'Museum'         if 'museums'        in cat else\\\n",
    "                        'Heritage Tree'  if 'heritage-trees' in cat else\\\n",
    "                        'Historic Site'  if 'historic-sites' in cat else\\\n",
    "                        'Library'        if 'libraries'      in cat else\\\n",
    "                        'Hotel'          if 'hotels'         in cat else\\\n",
    "                        cat\n",
    "    \n",
    "    return tmp.join(tmp.apply(lambda r: pairup((r['venue_lat'],r['venue_lng'])), axis=1))\n",
    "\n",
    "# get kml file paths\n",
    "kmls = {file.rstrip('.kml'):os.path.join(root,file) for root, dirs, files in os.walk('./data.gov.sg/venues') for file in files if file[-4:] == '.kml'}\n",
    "\n",
    "# parse kml files\n",
    "kmls = {cat: parseKML(cat, v) for cat,v in kmls.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - Combine data from all sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawdata: combining data from all sources\n",
    "rawdata = pd.concat(list(kmls.values()) + [venues], sort=True).reset_index(drop=True)\n",
    "rawdata = rawdata[~rawdata['name'].isna()]\n",
    "\n",
    "# catdata: name as index, each category as one column\n",
    "catdata = rawdata[['name','venue_cat']]\n",
    "catdata = catdata.drop('venue_cat', axis=1)\\\n",
    "                 .join(pd.get_dummies(catdata[['venue_cat']], prefix=\"\", prefix_sep=\"\"))\\\n",
    "                 .groupby('name').sum(axis=1)\n",
    "for cat in cats:\n",
    "    if cat not in catdata:\n",
    "        catdata[cat] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning data with K-means\n",
    "\n",
    "  First form the learning dataset by:\n",
    "  \n",
    "  1. Accept user's choice of importance among all categories;\n",
    "  2. Convert importance into a cutoff value for each category, by [category column].quantile(importance/10)\n",
    "  3. Cut-off every category column with its cutoff value\n",
    "  4. Normalize each column (category) to 0-1 by dividing it by its cut-off\n",
    "  5. Scale up column by its importance to reflect its relative importance\n",
    "  \n",
    "Then do KMeans on the dataset. Since KMeans depends on initial seeding centroids, multiple configurations are learnt where each KMeans will give a list of areas similar to user's need.\n",
    "\n",
    "The listed areas each gets a vote and the final area suggestions are determined by the votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper functions: learn()\n",
    "def learn(catdata, importance):\n",
    "    \n",
    "    # fit data: learning dataset\n",
    "    fitdata = catdata.apply(lambda r: normalize(r, importance[r.name]), axis=0)\n",
    "    fitdata = pd.concat([ pd.DataFrame([importance]), fitdata ], sort=True)\n",
    "    \n",
    "    # run K-means with different configurations,\n",
    "    # areas falling into the same group with the user's selection gets a vote\n",
    "    # final likelihood of matching areas are determined by the number of votes\n",
    "    votes = {}\n",
    "    for k in [3,5,19,27,40]:\n",
    "        for i in range(3):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=k*10+i).fit(fitdata)\n",
    "            choice = kmeans.labels_[0]\n",
    "\n",
    "            tmp = pd.DataFrame({'name': fitdata.index, 'label': kmeans.labels_}).drop(0)\n",
    "            for name in tmp[tmp['label']==choice]['name']:\n",
    "                votes[name] = votes.get(name, 0) + 1\n",
    "    result = pd.Series(votes)\n",
    "    \n",
    "    # return a dataframe of name, its latlng, and rank.\n",
    "    # the rank is the number of vote normalized by the max. vote then squared\n",
    "    # squaring a number between 0 and 1 further suppress small rank.\n",
    "    return pd.DataFrame({'name': result.index, 'votes': result, 'rank': (result/result.max())**2 })\\\n",
    "             .merge(rawdata[['name','lat','lng']].drop_duplicates('name'), on='name', how='left')\\\n",
    "             .sort_values('rank', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a form that accepts users' preference and\n",
    "# Draw suggestions on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n",
       "//disable auto-scrolling\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n",
    "//disable auto-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# group categories to simply user input. \n",
    "# i.e. user only consider 5 choices instead of all 22.\n",
    "form_cats = {'Food': ['American Restaurant','Asian Restaurant',],\n",
    "             'Hotel':['Hotel'],\n",
    "             'Life': ['Bank','Basketball Court','Church','Gym','Hospital','Laundry Service','Library','Market','Supermarket'],\n",
    "             'Rest': ['Café','Park','Shopping Mall'],\n",
    "             'Sightseeing': ['Attraction', 'Museum','Heritage Tree','Historic Site']}\n",
    "\n",
    "##### Helper function: on_button_clicked()\n",
    "def on_button_clicked(b):\n",
    "    with output, warnings.catch_warnings(), pd.option_context('display.max_colwidth', -1):\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        # get importance from sliders\n",
    "        importance = {v: form_cats_is[c].value for c, vs in form_cats.items() for v in vs }\n",
    "        \n",
    "        # get ranked dataframe \n",
    "        learndata  = catdata[list(importance.keys())]\n",
    "        rankeddata = learn(learndata, importance)\n",
    "        \n",
    "        # create map and add areas. Higher rank area is more visible.\n",
    "        centerLoc2 = np.mean(rankeddata[['lat','lng']], axis=0)\n",
    "        mapSuggest = folium.Map(location=centerLoc2, zoom_start=11.5)\n",
    "        for i, row in rankeddata.iterrows():\n",
    "            folium.Circle((row['lat'], row['lng']), RADIUS, row['name'], row['name'], color='#FF0000' if i==0 else None, fill=True, fill_color='#009900', fill_opacity=row['rank'])\\\n",
    "                  .add_to(mapSuggest)  \n",
    "        \n",
    "        # replace map\n",
    "        clear_output()\n",
    "        display(mapSuggest)\n",
    "        \n",
    "        # show first suggestion\n",
    "        fs = rankeddata.iloc[0]\n",
    "        fr = rawdata[rawdata['name']==fs['name']]\n",
    "        fp = fr[['PhotoURL','Description']].replace('',np.nan).dropna(axis=0).apply(lambda r: '<img src=\"%s\" height=180 width=240><br><font size=2>%s</font>'%(r['PhotoURL'] if r['PhotoURL'][0:4] == 'http' else 'http://%s'%r['PhotoURL'],r['Description']), axis=1)\n",
    "        thmb = '<br>'.join([fp.iloc[i*3:(i+1)*3].to_frame().transpose().to_html(header=False,index=False,escape=False,border=0).replace('<table','<table width=740').replace('<td>','<td width=240 valign=\"top\">') for i in range(3)])\n",
    "        \n",
    "        s = ''' <hr><hr><font size=5>Best choice: <b>{name}</b></font><br><font size=4>Address: {addr}</font><br><font size=3>Summary:</font><br>{stat}<br><font size=2><i>The following photos and descriptions are from data.gov.sg</i></font><br>{thmb}\n",
    "            '''.format(name = fs['name'], addr = fr['address'].dropna().iloc[0], stat = fr.groupby('venue_cat').apply(lambda df: pd.Series({'count':len(df)})).transpose().to_html(justify='center'), thmb = thmb)\n",
    "        display(HTML(s))\n",
    "        \n",
    "        # create a map showing venues in first suggestion\n",
    "        # https://getbootstrap.com/docs/3.3/components/#glyphicons-glyphs\n",
    "        mapFirst = folium.Map(location=(rankeddata['lat'][0],rankeddata['lng'][0]), zoom_start=17)\n",
    "        colors   = {k:c for k,c in zip(list(form_cats.keys()), randColor2(len(form_cats)))}\n",
    "        icons    = {'Food':'glyphicon glyphicon-cutlery', 'Hotel':'glyphicon glyphicon-home', \n",
    "                    'Life': 'briefcase', 'Rest':'heart','Sightseeing':'glyphicon glyphicon-camera'}\n",
    "        \n",
    "        for i, row in fr.iterrows():\n",
    "            color = [colors[k] for k,v in form_cats.items() if row['venue_cat'] in v] + ['#000000']\n",
    "            icon  = [icons[k]  for k,v in form_cats.items() if row['venue_cat'] in v] + ['cloud']\n",
    "            folium.Marker((row['venue_lat'], row['venue_lng']), row['venue'], row['venue'], icon=folium.Icon(icon=icon[0],color=color[0]))\\\n",
    "                  .add_to(mapFirst)\n",
    "        display(mapFirst)\n",
    "        \n",
    "np.random.seed(2)\n",
    "\n",
    "# create objects\n",
    "output  = Output()\n",
    "button  = Button(description='Go!')\n",
    "message = HTML('How important are they in your trip?')\n",
    "form_cats_is = {c: IntSlider(value=np.random.uniform(2,8),min=1,max=9,step=1,description=c,disabled=False,orientation='horizontal',readout=True,readout_format='d') for c in form_cats.keys()}\n",
    "\n",
    "# link on_button_clicked to button\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# show the form\n",
    "display(VBox([message] + list(form_cats_is.values()) + [button, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c01.png)\n",
    "![Image2](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c02.png)\n",
    "![Image3](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c03.png)\n",
    "![Image4](https://raw.githubusercontent.com/mwkwok/trip_planning_recommender/master/c04.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
